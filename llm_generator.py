# Created by erainm on 2025/11/26 10:42.
# IDEï¼šPyCharm 
# @Project: image_text_rag
# @Fileï¼šllm_generator
# @Description: LLMç”Ÿæˆå™¨

from multimodal_retriever import multimodal_retriever
import logging
from vector_manager import vector_manager
from milvus_manager import milvus_manager

logger = logging.getLogger(__name__)


class LLMGenerator:
    def __init__(self):
        from config import MODEL_CONFIG
        model_path = MODEL_CONFIG["llm"]["local_path"]
        self.model_path = model_path
        self.answer_mode = "strict"  # strict, extractive, balanced

    def set_answer_mode(self, mode: str):
        """è®¾ç½®ç­”æ¡ˆç”Ÿæˆæ¨¡å¼"""
        valid_modes = ["strict", "extractive", "balanced"]
        if mode in valid_modes:
            self.answer_mode = mode
            logger.info(f"ç­”æ¡ˆç”Ÿæˆæ¨¡å¼è®¾ç½®ä¸º: {mode}")
        else:
            logger.warning(f"æ— æ•ˆçš„æ¨¡å¼: {mode}, ä½¿ç”¨é»˜è®¤æ¨¡å¼")

    def generate_rag_answer(self, query: str) -> str:
        """ç”ŸæˆåŸºäºRAGçš„ç­”æ¡ˆ - ç¡®ä¿å›¾ç‰‡æ­£ç¡®æ˜¾ç¤º"""
        try:
            # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£å†…å®¹
            text_results, image_results = self.search_relevant_content(query, top_k=8)

            logger.info(f"æ£€ç´¢ç»“æœ: {len(text_results)} æ–‡æœ¬, {len(image_results)} å›¾ç‰‡")

            # 2. å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡æœ¬å†…å®¹ï¼Œåˆ™å°è¯•æ›´å®½æ¾çš„æ£€ç´¢
            if not text_results:
                logger.info("æœªæ‰¾åˆ°é«˜ç›¸å…³æ€§æ–‡æœ¬ï¼Œå°è¯•å®½æ¾æ£€ç´¢")
                text_results = self._loose_text_search(query, top_k=5)

            # 3. å¦‚æœæœ‰å›¾ç‰‡ï¼Œä¼˜å…ˆç¡®ä¿å›¾ç‰‡URLæ­£ç¡®
            for i, img in enumerate(image_results):
                # ç¡®ä¿å›¾ç‰‡URLæ ¼å¼æ­£ç¡®
                if not img['url'].startswith('/api/images/'):
                    # å°è¯•ä¿®å¤URLæ ¼å¼
                    if 'image_url' in img and img['image_url']:
                        img['url'] = img['image_url']
                    else:
                        # ä»æè¿°æˆ–å…¶ä»–å­—æ®µæ¨æ–­
                        logger.warning(f"å›¾ç‰‡ {i + 1} URLæ ¼å¼å¼‚å¸¸: {img['url']}")

                logger.info(f"å›¾ç‰‡ {i + 1} URL: {img['url']}")

            # 4. æ„å»ºæç¤ºè¯
            prompt = self._build_strict_rag_prompt(query, text_results, image_results)

            # 5. ç”Ÿæˆç­”æ¡ˆ
            response = self.generate_response(prompt, max_length=1024, temperature=0.1)

            # 6. æ·»åŠ å¼•ç”¨ä¿¡æ¯ï¼ˆåŒ…æ‹¬æ–‡æœ¬å’Œå›¾ç‰‡ï¼‰
            logger.info(f"æ·»åŠ å¼•ç”¨ä¿¡æ¯: {len(text_results)} æ–‡æœ¬, {len(image_results)} å›¾ç‰‡")
            response = self._add_references(response, text_results, image_results)
            
            # 7. å¦‚æœæœ‰ç›¸å…³å›¾ç‰‡ï¼Œç›´æ¥æ˜¾ç¤ºå›¾ç‰‡
            if image_results:
                logger.info(f"ç›´æ¥æ˜¾ç¤º {len(image_results)} å¼ å›¾ç‰‡")
                response = self._add_image_references(response, image_results)

            return response

        except Exception as e:
            logger.error(f"RAGç­”æ¡ˆç”Ÿæˆå¤±è´¥: {e}")
            return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°é”™è¯¯: {str(e)}"

    def _loose_text_search(self, query: str, top_k: int = 5):
        """å®½æ¾çš„æ–‡æœ¬æœç´¢"""
        try:
            # ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_embedding = vector_manager.get_text_embeddings_batch([query])[0]
            
            # æœç´¢æ›´å¤šç»“æœ
            results = milvus_manager.search(query_embedding.tolist(), top_k=top_k*2)
            
            # è¿‡æ»¤æ–‡æœ¬ç»“æœï¼Œä½¿ç”¨æ›´ä½çš„é˜ˆå€¼
            text_results = []
            for item in results:
                if item['content_type'] == 'text':
                    # è®¡ç®—ç›¸å…³æ€§ä½†ä½¿ç”¨æ›´ä½çš„é˜ˆå€¼
                    relevance = self._calculate_loose_relevance(query, item['content'])
                    
                    if relevance > 0.01:  # éå¸¸ä½çš„é˜ˆå€¼
                        text_results.append({
                            'content': item['content'],
                            'source': item['source'],
                            'page': item['page'],
                            'score': item['score'],
                            'relevance': relevance,
                            'type': 'text'
                        })

            # æŒ‰ç›¸å…³æ€§æ’åº
            text_results.sort(key=lambda x: x['relevance'], reverse=True)
            return text_results[:top_k]

        except Exception as e:
            logger.error(f"å®½æ¾æ–‡æœ¬æœç´¢å¤±è´¥: {e}")
            return []

    def _calculate_loose_relevance(self, query: str, text: str) -> float:
        """è®¡ç®—å®½æ¾çš„ç›¸å…³æ€§åˆ†æ•°"""
        try:
            # ç®€å•çš„å…³é”®è¯åŒ¹é…
            query_words = set(query.lower().split())
            text_words = set(text.lower().split())
            
            if not query_words:
                return 0.0
                
            # è®¡ç®—é‡å æ¯”ä¾‹
            overlap = len(query_words.intersection(text_words))
            return overlap / len(query_words)
            
        except:
            return 0.0

    def _generate_fallback_answer(self, query: str, text_results: list, image_results: list) -> str:
        """ç”Ÿæˆå¤‡é€‰ç­”æ¡ˆ"""
        if not text_results and not image_results:
            return "åœ¨æ–‡æ¡£ä¸­æ²¡æœ‰æ‰¾åˆ°ä¸æ‚¨é—®é¢˜ç›¸å…³çš„å†…å®¹ã€‚"

        answer = "æ ¹æ®æ–‡æ¡£å†…å®¹ï¼š\n\n"

        if text_results:
            answer += "**ç›¸å…³æ–‡æœ¬å†…å®¹ï¼š**\n"
            for i, text in enumerate(text_results[:3]):
                answer += f"{i + 1}. {text['content']} (æ¥è‡ª: {text['source']} ç¬¬{text['page']}é¡µ)\n\n"

        if image_results:
            answer += "**ç›¸å…³å›¾ç‰‡ï¼š**\n"
            for i, img in enumerate(image_results[:2]):
                answer += f"- {img['description']} (æ¥è‡ª: {img['source']} ç¬¬{img['page']}é¡µ)\n"

        return answer

    def _generate_error_answer(self, query: str, error: str) -> str:
        """ç”Ÿæˆé”™è¯¯ç­”æ¡ˆ"""
        return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶é‡åˆ°æŠ€æœ¯é—®é¢˜ï¼š{error}\n\né—®é¢˜ï¼š{query}"

    def _post_process_response(self, response: str, text_results: list, query: str) -> str:
        """åå¤„ç†ï¼šç¡®ä¿å›ç­”åŸºäºåŸæ–‡"""
        # æ£€æŸ¥å›ç­”æ˜¯å¦åç¦»åŸæ–‡
        if self._is_response_deviated(response, text_results):
            logger.warning("æ£€æµ‹åˆ°å›ç­”åç¦»åŸæ–‡ï¼Œè¿›è¡Œä¿®æ­£")
            return self.generate_extractive_answer(query, text_results, [])

        return response

    def _is_response_deviated(self, response: str, text_results: list) -> bool:
        """æ£€æŸ¥å›ç­”æ˜¯å¦åç¦»åŸæ–‡"""
        if not text_results:
            return False

        # ç®€å•çš„æ£€æŸ¥ï¼šå›ç­”ä¸­æ˜¯å¦åŒ…å«åŸæ–‡çš„å…³é”®è¯
        original_keywords = set()
        for text in text_results[:3]:
            words = text['content'].lower().split()[:10]  # å–å‰10ä¸ªè¯ä½œä¸ºå…³é”®è¯
            original_keywords.update(words)

        response_words = set(response.lower().split())
        overlap = len(original_keywords.intersection(response_words))

        # å¦‚æœé‡å åº¦å¤ªä½ï¼Œå¯èƒ½åç¦»åŸæ–‡
        deviation_ratio = overlap / len(original_keywords) if original_keywords else 0
        return deviation_ratio < 0.2  # å¦‚æœé‡å åº¦ä½äº20%ï¼Œè®¤ä¸ºåç¦»

    def generate_response(self, prompt: str, max_length: int = 512, temperature: float = 0.7) -> str:
        """ç”ŸæˆLLMå“åº”"""
        try:
            from transformers import AutoModelForCausalLM, AutoTokenizer
            import torch

            # åŠ è½½æ¨¡å‹å’Œtokenizer
            tokenizer = AutoTokenizer.from_pretrained(
                self.model_path,
                trust_remote_code=True,
                local_files_only=True
            )

            model = AutoModelForCausalLM.from_pretrained(
                self.model_path,
                torch_dtype=torch.float32,
                low_cpu_mem_usage=True,
                trust_remote_code=True,
                local_files_only=True,
                device_map="auto" if torch.cuda.is_available() else None
            )

            # ç¼–ç è¾“å…¥
            inputs = tokenizer(
                prompt,
                return_tensors="pt",
                truncation=True,
                max_length=2048,
                padding=True
            )

            # ç§»åŠ¨åˆ°æ¨¡å‹è®¾å¤‡
            inputs = {k: v.to(model.device) for k, v in inputs.items()}

            with torch.no_grad():
                outputs = model.generate(
                    **inputs,
                    max_new_tokens=max_length,
                    do_sample=True,
                    temperature=temperature,
                    top_p=0.9,
                    pad_token_id=tokenizer.eos_token_id,
                    eos_token_id=tokenizer.eos_token_id,
                    repetition_penalty=1.1
                )

            # è§£ç å“åº”
            response = tokenizer.decode(outputs[0], skip_special_tokens=True)

            # ç§»é™¤è¾“å…¥éƒ¨åˆ†
            if response.startswith(prompt):
                response = response[len(prompt):].strip()

            return response

        except Exception as e:
            logger.error(f"LLMç”Ÿæˆå¤±è´¥: {e}")
            return f"æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶å‡ºç°é”™è¯¯: {str(e)}"

    def search_relevant_content(self, query: str, top_k: int = 8):
        """æœç´¢ç›¸å…³çš„æ–‡æ¡£å†…å®¹ - å¢å¼ºå›¾ç‰‡æ£€ç´¢"""
        try:
            # ä½¿ç”¨å¢å¼ºçš„æ··åˆæ£€ç´¢
            text_results, image_results = multimodal_retriever.enhanced_hybrid_search(query, top_k=top_k)

            # å¦‚æœæ–‡æœ¬ç»“æœå¤ªå°‘ï¼Œå°è¯•å®½æ¾æ£€ç´¢
            if len(text_results) < 2:
                logger.info("æ–‡æœ¬ç»“æœè¾ƒå°‘ï¼Œä½¿ç”¨å®½æ¾æ£€ç´¢")
                loose_text_results = self._loose_text_search(query, top_k=5)
                # åˆå¹¶ç»“æœï¼Œå»é‡
                existing_contents = {text['content'][:50] for text in text_results}  # ä½¿ç”¨å‰50ä¸ªå­—ç¬¦å»é‡
                for text in loose_text_results:
                    if text['content'][:50] not in existing_contents:
                        text_results.append(text)
                        existing_contents.add(text['content'][:50])

            # å¦‚æœå›¾ç‰‡ç»“æœå¤ªå°‘ï¼Œä½¿ç”¨å¼ºåˆ¶å›¾ç‰‡æœç´¢
            if len(image_results) < 2:
                logger.info("å›¾ç‰‡ç»“æœè¾ƒå°‘ï¼Œä½¿ç”¨å¼ºåˆ¶å›¾ç‰‡æœç´¢")
                force_images = multimodal_retriever.force_image_search(query, top_k=3)
                # åˆå¹¶ç»“æœï¼Œå»é‡
                existing_urls = {img['url'] for img in image_results}
                for img in force_images:
                    if img['url'] not in existing_urls and img['url']:  # ç¡®ä¿URLä¸ä¸ºç©º
                        image_results.append(img)
                        existing_urls.add(img['url'])

            logger.info(f"æœ€ç»ˆæ£€ç´¢ç»“æœ: {len(text_results)} æ–‡æœ¬, {len(image_results)} å›¾ç‰‡")

            return text_results, image_results

        except Exception as e:
            logger.error(f"å†…å®¹æ£€ç´¢å¤±è´¥: {e}")
            # æœ€åçš„åå¤‡æ–¹æ¡ˆ
            try:
                loose_text_results = self._loose_text_search(query, top_k=3)
                force_images = multimodal_retriever.force_image_search(query, top_k=3)
                logger.info(f"ä½¿ç”¨åå¤‡æ–¹æ¡ˆæ£€ç´¢ç»“æœ: {len(loose_text_results)} æ–‡æœ¬, {len(force_images)} å›¾ç‰‡")
                return loose_text_results, force_images
            except:
                return [], []

    def _build_strict_rag_prompt(self, query: str, text_results: list, image_results: list) -> str:
        """æ„å»ºä¸¥æ ¼çš„RAGæç¤ºè¯ - ä¿®å¤ç‰ˆæœ¬"""

        # æ„å»ºç³»ç»Ÿæç¤º
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£é—®ç­”åŠ©æ‰‹ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§æä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ã€‚

é‡è¦è¦æ±‚ï¼š
1. **å¿…é¡»åŸºäºåŸæ–‡å›ç­”**ï¼šåªä½¿ç”¨æä¾›çš„æ–‡æ¡£å†…å®¹
2. **å¿…é¡»ç»™å‡ºå…·ä½“ç­”æ¡ˆ**ï¼šä¸èƒ½åªè¯´"æ–‡æ¡£ä¸­æœ‰ç›¸å…³ä¿¡æ¯"ï¼Œè¦ç»™å‡ºå…·ä½“å†…å®¹
3. **ç›´æ¥å¼•ç”¨åŸæ–‡**ï¼šå°½é‡ä½¿ç”¨åŸæ–‡çš„è¯å¥
4. **æ³¨æ˜æ¥æº**ï¼šæ¯ä¸ªä¿¡æ¯ç‚¹éƒ½è¦æ³¨æ˜æ¥è‡ªå“ªä¸ªæ–‡æ¡£ç¬¬å‡ é¡µ
5. **å¦‚æœä¿¡æ¯ä¸è¶³**ï¼šæ˜ç¡®è¯´"æ ¹æ®æä¾›çš„æ–‡æ¡£å†…å®¹ï¼Œæ— æ³•å®Œæ•´å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œä½†ç›¸å…³å†…å®¹åŒ…æ‹¬ï¼š..."
6. **å¿…é¡»å›ç­”**ï¼šæ— è®ºå¦‚ä½•éƒ½è¦ç»™å‡ºæœ‰æ„ä¹‰çš„å›ç­”

ç¦æ­¢äº‹é¡¹ï¼š
- ä¸è¦æ·»åŠ å¤–éƒ¨çŸ¥è¯†
- ä¸è¦è¿›è¡Œåˆ›é€ æ€§å‘æŒ¥
- ä¸è¦åªè¯´"æ–‡æ¡£ä¸­æœ‰ç›¸å…³ä¿¡æ¯"è€Œä¸ç»™å‡ºå…·ä½“å†…å®¹
"""

        prompt = f"{system_prompt}\n\nç”¨æˆ·é—®é¢˜: {query}\n\n"

        # æ·»åŠ æ–‡æœ¬å†…å®¹
        if text_results:
            prompt += "**ç›¸å…³æ–‡æ¡£åŸæ–‡:**\n\n"
            for i, text in enumerate(text_results[:5]):
                source_info = f"{text['source']} ç¬¬{text['page']}é¡µ"
                relevance = f"(ç›¸å…³æ€§: {text['relevance']:.3f})"

                prompt += f"ã€åŸæ–‡ç‰‡æ®µ {i + 1}ã€‘{relevance} - {source_info}\n"
                # åŒ…å«å®Œæ•´çš„å†…å®¹ï¼Œä¸åªæ˜¯æˆªæ–­çš„
                prompt += f"{text['content']}\n\n"
        else:
            prompt += "**æ–‡æ¡£åŸæ–‡:** æœªæ‰¾åˆ°ç›¸å…³æ–‡æœ¬å†…å®¹ã€‚\n\n"
            # å³ä½¿æ²¡æœ‰æ‰¾åˆ°æ–‡æœ¬ï¼Œä¹Ÿæ·»åŠ ä¸€ä¸ªé€šç”¨è¯´æ˜
            prompt += "æ³¨æ„ï¼šç³»ç»Ÿæœªæ‰¾åˆ°ä¸æ‚¨çš„é—®é¢˜é«˜åº¦ç›¸å…³çš„æ–‡æœ¬å†…å®¹ã€‚\n\n"

        # æ·»åŠ å›¾ç‰‡æè¿°
        if image_results:
            prompt += "**ç›¸å…³å›¾ç‰‡ä¿¡æ¯:**\n\n"
            for i, img in enumerate(image_results[:5]):  # å¢åŠ åˆ°5å¼ å›¾ç‰‡
                score = f"(åŒ¹é…åº¦: {img['score']:.3f})"
                prompt += f"ã€å›¾ç‰‡ {i + 1}ã€‘{img['description']} {score} æ¥è‡ª: {img['source']} ç¬¬{img['page']}é¡µ\n\n"

        prompt += f"""
**è¯·åŸºäºä»¥ä¸ŠåŸæ–‡å†…å®¹ç›´æ¥å›ç­”è¿™ä¸ªé—®é¢˜: "{query}"**

ä½ çš„å›ç­”å¿…é¡»åŒ…å«ï¼š
1. åŸºäºåŸæ–‡çš„å…·ä½“ç­”æ¡ˆ
2. å¼•ç”¨å…·ä½“çš„ä¿¡æ¯æ¥æº
3. å¦‚æœæœ‰å›¾ç‰‡ï¼ŒæåŠå›¾ç‰‡å†…å®¹

å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–‡æœ¬å†…å®¹ï¼Œè¯·æ˜ç¡®è¯´æ˜è¿™ä¸€ç‚¹ï¼Œå¹¶å°è¯•åŸºäºå›¾ç‰‡ä¿¡æ¯å›ç­”é—®é¢˜ã€‚

ç°åœ¨è¯·ç›´æ¥å›ç­”é—®é¢˜:
"""
        return prompt

    def generate_extractive_answer(self, query: str, text_results: list, image_results: list) -> str:
        """ç”ŸæˆåŸºäºåŸæ–‡æŠ½å–çš„ç­”æ¡ˆ"""
        try:
            if not text_results:
                return "æ–‡æ¡£ä¸­æ²¡æœ‰æ‰¾åˆ°ä¸é—®é¢˜ç›¸å…³çš„ä¿¡æ¯ã€‚"

            # ç›´æ¥ç»„åˆæœ€ç›¸å…³çš„æ–‡æœ¬ç‰‡æ®µ
            relevant_contents = []
            for i, text in enumerate(text_results[:3]):
                if text['relevance'] > 0.4:  # åªä½¿ç”¨ç›¸å…³æ€§é«˜çš„ç‰‡æ®µ
                    source_info = f"ï¼ˆæ¥è‡ª: {text['source']} ç¬¬{text['page']}é¡µï¼‰"
                    relevant_contents.append(f"{text['content']} {source_info}")

            if not relevant_contents:
                return "æ–‡æ¡£ä¸­è™½ç„¶æœ‰ç›¸å…³å†…å®¹ï¼Œä½†ç›¸å…³æ€§è¾ƒä½ï¼Œæ— æ³•å‡†ç¡®å›ç­”ã€‚"

            # ç›´æ¥ç»„åˆåŸæ–‡ç‰‡æ®µ
            answer = "æ ¹æ®æ–‡æ¡£å†…å®¹ï¼š\n\n"
            for i, content in enumerate(relevant_contents):
                answer += f"{i + 1}. {content}\n\n"

            # æ·»åŠ å›¾ç‰‡ä¿¡æ¯
            if image_results:
                answer += "ç›¸å…³å›¾ç‰‡ä¿¡æ¯ï¼š\n"
                for img in image_results[:2]:
                    answer += f"- {img['description']}ï¼ˆ{img['source']} ç¬¬{img['page']}é¡µï¼‰\n"

            return answer

        except Exception as e:
            logger.error(f"æŠ½å–å¼ç­”æ¡ˆç”Ÿæˆå¤±è´¥: {e}")
            return self.generate_rag_answer(query)  # å›é€€åˆ°ç”Ÿæˆå¼æ–¹æ³•

    def _add_references(self, response: str, text_results: list, image_results: list) -> str:
        """åœ¨å›ç­”ä¸­æ·»åŠ å¼•ç”¨ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ–‡æœ¬æ¥æºå’Œå›¾ç‰‡"""
        reference_section = "\n\n---\n**å¼•ç”¨æ—¥æœŸå’Œå›¾ç‰‡**\n"
        
        # æ·»åŠ æ–‡æœ¬å¼•ç”¨
        if text_results:
            reference_section += "\n**ç›¸å…³æ–‡æœ¬å†…å®¹:**\n"
            for i, text in enumerate(text_results[:5]):  # æ˜¾ç¤ºæœ€å¤š5ä¸ªæ–‡æœ¬å¼•ç”¨
                source_info = f"{text['source']} ç¬¬{text['page']}é¡µ"
                relevance = f"(ç›¸å…³æ€§: {text['relevance']:.2f})"
                reference_section += f"\n[{i+1}] {relevance} {source_info}\n"
                # æˆªå–éƒ¨åˆ†å†…å®¹ä½œä¸ºå¼•ç”¨
                content_preview = text['content'][:200] + "..." if len(text['content']) > 200 else text['content']
                reference_section += f"    {content_preview}\n"
        
        # æ·»åŠ å›¾ç‰‡å¼•ç”¨
        if image_results:
            reference_section += "\n**ç›¸å…³å›¾ç‰‡:**\n"
            for i, img in enumerate(image_results[:5]):  # æ˜¾ç¤ºæœ€å¤š5å¼ å›¾ç‰‡
                source_info = f"{img['source']} ç¬¬{img['page']}é¡µ"
                score = f"(åŒ¹é…åº¦: {img['score']:.2f})"
                reference_section += f"\n[{i+1}] {score} {source_info}\n"
                reference_section += f"    æè¿°: {img.get('description', 'æ— æè¿°')}\n"
        
        return response + reference_section

    def _add_image_references(self, response: str, image_results: list) -> str:
        """åœ¨å›ç­”ä¸­æ·»åŠ çœŸå®çš„å›¾ç‰‡æ˜¾ç¤º - ç›´æ¥æ˜¾ç¤ºå›¾ç‰‡è€Œä¸æ˜¯æè¿°"""
        if not image_results:
            return response

        logger.info(f"å‡†å¤‡ç›´æ¥æ˜¾ç¤º {len(image_results)} å¼ å›¾ç‰‡")

        # å¯¼å…¥é…ç½®è·å–æ­£ç¡®çš„ç«¯å£å·
        from config import SYSTEM_CONFIG
        port = SYSTEM_CONFIG.get('port', 6001)

        image_section = "\n\n---\n**ğŸ–¼ï¸ ç›¸å…³å›¾ç‰‡**\n\n"

        displayed_count = 0
        for i, img in enumerate(image_results):
            if displayed_count >= 5:  # å¢åŠ åˆ°æœ€å¤šæ˜¾ç¤º5å¼ å›¾ç‰‡
                break

            image_url = img['url']
            description = img.get('description', 'æ–‡æ¡£å›¾ç‰‡')
            source = img['source']
            page = img['page']

            # æ„å»ºå®Œæ•´çš„å›¾ç‰‡URLï¼Œä½¿ç”¨æ­£ç¡®çš„ç«¯å£å·
            if image_url.startswith('/api/images/'):
                full_url = f"http://localhost:{port}{image_url}"
            else:
                # å°è¯•ä»å…¶ä»–æ ¼å¼æå–æ–‡ä»¶å
                filename = image_url.split('/')[-1] if '/' in image_url else image_url
                full_url = f"http://localhost:{port}/api/images/{filename}"

            logger.info(f"æ˜¾ç¤ºå›¾ç‰‡ {i + 1}: {full_url}")

            # ç›´æ¥æ˜¾ç¤ºå›¾ç‰‡ï¼Œä½¿ç”¨æ›´å¤§çš„å°ºå¯¸å’Œæ›´å¥½çš„å¸ƒå±€
            image_section += f"""
    <div style="
        border: 2px solid #3498db; 
        border-radius: 12px; 
        padding: 20px; 
        margin: 20px 0; 
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        box-shadow: 0 4px 12px rgba(0,0,0,0.1);
    ">
        <div style="text-align: center; margin-bottom: 15px;">
            <img 
                src="{full_url}" 
                alt="{description}"
                style="
                    max-width: 90%; 
                    max-height: 400px; 
                    height: auto; 
                    border-radius: 8px; 
                    border: 1px solid #bdc3c7;
                    box-shadow: 0 2px 8px rgba(0,0,0,0.15);
                    transition: transform 0.3s ease;
                "
                onmouseover="this.style.transform='scale(1.02)'"
                onmouseout="this.style.transform='scale(1)'"
                onerror="
                    this.onerror=null; 
                    this.src='https://via.placeholder.com/600x400/95a5a6/ffffff?text=å›¾ç‰‡åŠ è½½å¤±è´¥'; 
                    this.alt='å›¾ç‰‡åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥å›¾ç‰‡URL';
                    console.error('å›¾ç‰‡åŠ è½½å¤±è´¥:', this.src);
                "
                onload="console.log('å›¾ç‰‡åŠ è½½æˆåŠŸ:', this.src)"
            >
        </div>
        <div style="
            text-align: center; 
            font-size: 14px; 
            color: #2c3e50; 
            background: rgba(255,255,255,0.8); 
            padding: 10px; 
            border-radius: 6px;
            border-left: 4px solid #3498db;
        ">
            <div style="font-weight: bold; margin-bottom: 5px;">
                ğŸ“¸ å›¾ç‰‡ {i + 1} - {description}
            </div>
            <div style="font-size: 12px; color: #7f8c8d;">
                ğŸ“ æ¥æº: {source} | ğŸ“„ é¡µç : {page}
            </div>
        </div>
    </div>
    """
            displayed_count += 1

        if displayed_count > 0:
            # æ·»åŠ ä¸€äº›CSSæ ·å¼ç¡®ä¿å›¾ç‰‡æ˜¾ç¤ºæ­£å¸¸
            image_section += """
    <style>
    @media (max-width: 768px) {
        .image-container img {
            max-width: 100% !important;
        }
    }
    </style>
    """

        return response + image_section
